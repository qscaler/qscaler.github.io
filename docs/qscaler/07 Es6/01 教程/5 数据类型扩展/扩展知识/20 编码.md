

### 扩展

[小姿势：锟斤拷是怎么出现的？](https://zhuanlan.zhihu.com/p/45695434)
[https://www.cnblogs.com/MrLiuZF/p/15216740.html](https://www.cnblogs.com/MrLiuZF/p/15216740.html)

[https://www.jianshu.com/p/9c9073e601d7](https://www.jianshu.com/p/9c9073e601d7)
[https://blog.csdn.net/hongsong673150343/article/details/88584753](https://blog.csdn.net/hongsong673150343/article/details/88584753)
[https://zhuanlan.zhihu.com/p/427488961](https://zhuanlan.zhihu.com/p/427488961)
[https://blog.csdn.net/u010783226/article/details/103061061](https://blog.csdn.net/u010783226/article/details/103061061)
[https://www.zhihu.com/question/485282740](https://www.zhihu.com/question/485282740)
[字符编码笔记：ASCII，Unicode 和 UTF-8](http://www.ruanyifeng.com/blog/2007/10/ascii_unicode_and_utf-8.html)
[ASCII码一览表，ASCII码对照表](http://c.biancheng.net/c/ascii/)
[字符编码那点事：快速理解ASCII、Unicode、GBK和UTF-8](https://zhuanlan.zhihu.com/p/38333902)
[字符编码那点事：快速理解ASCII、Unicode、GBK和UTF-8](https://zhuanlan.zhihu.com/p/427488961)

[在线进制转换](https://jisuan5.com/hexadecimal-to-decimal/)
[https://zhuanlan.zhihu.com/p/64330745](https://zhuanlan.zhihu.com/p/64330745)
[Unicode编码表/0000-0FFF](https://www.cnblogs.com/csguo/p/7401874.html)
[Unicode 字符集](https://unicode-table.com/cn/)
[字符编码的概念](https://blog.csdn.net/guxiaonuan/article/details/78678043)
[utf-16](https://zhuanlan.zhihu.com/p/27827951)


[js编码方式](https://blog.51cto.com/u_15914240/5946530)

### 一  ASCII
1. 简介
    ASCII（American Standard Code for Information Interchange，美国信息互换标准代码）是一套基于拉丁字母的字符编码，共收录了 128 个字符，用一个字节就可以存储，它等同于国际标准 ISO/IEC 646。

    ASCII 编码于 1967 年第一次发布，最后一次更新是在 1986 年，迄今为止共收录了 128 个字符，包含了基本的拉丁字母（英文字母）、阿拉伯数字（也就是 1234567890）、标点符号（,.!等）、特殊符号（@#$%^&等）以及一些具有控制功能的字符（往往不会显示出来）。

    ASCII 编码是美国人给自己设计的，他们并没有考虑欧洲那些扩展的拉丁字母，也没有考虑韩语和日语，我大中华几万个汉字更是不可能被重视。计算机也是美国人发明的，起初使用的就是 ASCII 码，只能显示英文字符。各个国家为了让本国公民也能正常使用计算机，开始效仿 ASCII 开发自己的字符编码，例如 ISO/IEC 8859（欧洲字符集）、shift_Jis（日语字符集）、GBK（中文字符集）等


    ASCII表是基于英语来编写的，其中包含了英文的大小写字母，以及数字0-9，各种符号。

    之前的ASCII表是0-127，共128个字符。

    但是随着科技的不断的进步，先前定义的ASCII 不能满足大家的需求. 后来ASCII 的表有扩展到了256个字符。？？？

2. ASCII 码表
    如上表：每一个ASCII 都有3部分组成. ASCII值、16进制、控制字符。
    其中ASCII值就是控制字符对应的十进制数值，16进制和ASCII值是对应的，控制字符就是可以表示的字符。

3.  对控制字符的解释
    ASCII 编码中第 0~31 个字符（开头的 32 个字符）以及第 127 个字符（最后一个字符）都是不可见的（无法显示），但是它们都具有一些特殊功能，所以称为控制字符（ Control Character）或者功能码（Function Code）。

    这 33 个控制字符大都与通信、数据存储以及老式设备有关，有些在现代电脑中的含义已经改变了。

    也有人将 ASCII 编码分成两部分：
    前 128 个字符称为基本 ASCII，包含常见字符；
    后 128 个字符称为扩展 ASCII，包含一些特殊字符。  但是不管怎样，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段


4.  java  char类型
    类型	 存储需求	取值范围	            默认值
    char	2字节	    \u0000 ~ \uffff	      \u0000(空字符)

    char类型的值可以表示为十六进制值，从\u0000～\uffff。这里是\u充当了一个转义序列的功能，同时\u转义序列是可以出现在字符常量或字符串，所以使用注释和参数的时候，要注意一下


5. Unicode 编码（国际标准字符集）

    世界上存在着多种编码方式，同一个二进制数字可以被解释成不同的符号。 因此，要想打开一个文本文件，就必须知道它的编码方式，否则用错误的编码方式解读，就会出现乱码。
    这就是为什么文件经常出现乱码，因为编码和解码用的编码方式不一样，可以想象，如果有一种编码，将世界上所有的符号都纳入其中。每一个符号都给予一个独一无二的编码，那么乱码问题就会消失。这就是 Unicode，就像它的名字都表示的，这是一种所有符号的编码。

    Unicode 为世界上所有字符都分配了一个唯一的数字编号，这个编号范围从 0x000000 到 0x10FFFF(0~1114111) (**十六进制**)，有 110 多万，每个字符都有一个唯一的 Unicode 编号，**这个编号一般写成 16 进制，在前面加上 U+**。例如：

    U+9A6C表示汉字马，

    U+4E25表示汉字严

    U+0639表示阿拉伯字母Ain，

    U+0041表示英语的大写字母A，

    Unicode 就相当于一张表，**建立了字符与编号之间的联系**


    在认识UTF-16前，我们需要认识Unicode Unicode 字符集的编码范围是 0x000000 - 0x10FFFF(0~1114111)，因此需要 1 到 3 个字节来表示

    Unicode其实相当于一本很厚的字典，里面储存了世界上所有语言的字符，使用Unicode码点唯一地对应一个字符。

    Unicode是没有规定字符对应的二进制码占用的空间是多少，那么问题来了，以“汉”字为例，它的Unicode码点为0x6c49，对应的二进制为110110001001001，也就是15位二进制，也就说明了，这个字需要用2个字节去存储这个字，那么，对于其他字体，很有可能出现3个字节，或者更多的字节去存储，对于计算机来说，计算机怎么知道这两个字节表示的是一个字符，而不是与后面的字节形成一个字符?

    所以，为了解决Unicode的这个问题，新的编码方式UTF-8、UTF-16和UTF-32就出现了

    十六进制--->十进制
    16进制就是逢16进1，但我们只有0~9这十个数字，所以我们用A，B，C，D，E，F这六个字母来分别表示10，11，12，13，14，15。字母不区分大小写。
    十六进制数的第0位的权值为16的0次方，第1位的权值为16的1次方，第2位的权值为16的2次方……
    所以，在第N（N从0开始）位上，如果是是数 X （X 大于等于0，并且X小于等于 15，即：F）表示的大小为 X * 16的N次方。
    假设有一个十六进数 2AF5, 那么如何换算成10进制？
    用竖式计算：
    2AF5换算成10进制:
    第0位：`5*16^0=5`
    第1位：`F*16^1==15*16^1=240`
    第2位：`A*16^2==10*16^2=2560`
    第3位：`2*16^3==8192`
    直接计算就是：算成10进制:`5*16^0+15*16^1+10*16^2+2*16^3`=10997 
    可以看出，所有进制换算成10进制，关键在于各自的权值不同
  
    以0x 或者x开始的数据表示16进制 备 注 0是数字0，不是字母O
    0x10FFFF
    15*16^0+15*16^1+15*16^2+15*16^3+0*16^4+1*16^5=1114111


3. UTF-8、UTF-16和UTF-32

    UTF 是 Unicode Transformation Format 的缩写，意思是“Unicode转换格式”，后面的数字表明至少使用多少个比特位（Bit）来存储字符。

    Unicode 1 码点转2进制 2 (一定规则,utf-8,16 ,32 规则都不一样)插进去 3 再转16进制

    (个人认为：**其实我们可以简单的把前面的1的个数看成字节数**)
    U-00000000 – U-0000007F: 0xxxxxxx
    U-00000080 – U-000007FF: 110xxxxx 10xxxxxx
    U-00000800 – U-0000FFFF: 1110xxxx 10xxxxxx 10xxxxxx
    U-00010000 – U-001FFFFF: 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
    U-00200000 – U-03FFFFFF: 111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
    U-04000000 – U-7FFFFFFF: 1111110x 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
    
    


    Unicode 可以使用的编码有三种，分别是：
        UFT-8：一种变长的编码方案，使用 1~6 个字节来存储；
            上面是UTF-8的编码规则，规则主要分为两部分。
                1. 如果Unicode码小于等于127，即ASCII码。则仍使用ASCII的编码格式，最高位为0，其余7位表示0-127。
                2. 如果，Unicode码大于127，以大端表示。然后从低位开始，每次取6位，加上高位的10，组成一个字节，直到不足6位。假设前面一共组成了n个字节，那么把前n+1位都标记为1，其余位标记为0。然后加上不足的6位，组成UTF-8编码的头部字节。最后把这些字节从低位到高位，拼成一串编码。
        UTF-16：介于 UTF-8 和 UTF-32 之间，使用 2 个或者 4 个字节来存储，长度既固定又可变。
            对于 Unicode 编号范围在 0 ~ FFFF 之间的字符，UTF-16 使用两个字节存储，并且直接存储 Unicode 编号，不用进行编码转换，这跟 UTF-32 非常类似。
            对于 Unicode 编号范围在 10000~10FFFF 之间的字符，UTF-16 使用四个字节存储，具体来说就是：将字符编号的所有比特位分成两部分，较高的一些比特位用一个值介于 D800~DBFF 之间的双字节存储，较低的一些比特位（剩下的比特位）用一个值介于 DC00~DFFF 之间的双字节存储。
            位于 D800~0xDFFF 之间的 Unicode 编码是特别为四字节的 UTF-16 编码预留的，所以不应该在这个范围内指定任何字符。如果你真的去查看 Unicode 字符集，会发现这个区间内确实没有收录任何字符。
            UTF-16 要求在制定 Unicode 字符集时必须考虑到编码问题，所以真正的 Unicode 字符集也不是随意编排字符的

        UFT-32：一种固定长度的编码方案，不管字符编号大小，始终使用 4 个字节来存储；
            UTF-32 是固定长度的编码，始终占用 4 个字节，足以容纳所有的 Unicode 字符，所以直接存储 Unicode 编号即可，不需要任何编码转换。浪费了空间，提高了效率。
            UTF-32 的优点在于，转换规则简单直观，查找效率高。缺点在于浪费空间，同样内容的英语文本，它会比 ASCII 编码大四倍。这个缺点很致命，导致实际上没有人使用这种编码方法，HTML 5 标准就明文规定，网页不得编码成 UTF-32。

                 

    GB2312、Shift-JIS 等国家（地区）字符集怎么编码
        GB2312、GBK、Shift-JIS 等特定国家的字符集都是在 ASCII 的基础上发展起来的，它们都兼容 ASCII，所以只能采用变长的编码方案：用一个字节存储 ASCII 字符，用多个字节存储本国字符。
        以 GB2312 为例，该字符集收录的字符较少，所以使用 1~2 个字节编码。
        对于 ASCII 字符，使用一个字节存储，并且该字节的最高位是 0；
        对于中国的字符，使用两个字节存储，并且规定每个字节的最高位都是 1。

        由于单字节和双字节的最高位不一样，所以很容易区分一个字符到底用了几个字节。

    宽字符和窄字符（多字节字符）
        有的编码方式采用 1~n 个字节存储，是变长的，例如 UTF-8、GB2312、GBK 等；如果一个字符使用了这种编码方式，我们就将它称为多字节字符，或者窄字符。
        有的编码方式是固定长度的，不管字符编号大小，始终采用 n 个字节存储，例如 UTF-32、UTF-16 等；如果一个字符使用了这种编码方式，我们就将它称为宽字符。
        Unicode 字符集可以使用窄字符的方式存储，也可以使用宽字符的方式存储；GB2312、GBK、Shift-JIS 等国家编码一般都使用窄字符的方式存储；ASCII 只有一个字节，无所谓窄字符和宽字符。


    <!-- 把UTF8按GBK解析，类似于把英语强行按汉语拼音来解释?? -->

    设备在显示字符的时候，会把不能显示的字符显示为符号�，即“\ufffd”。

    是的，终端显示字符的时候，还有一个显示字符集，这里就不展开了。
    “\ufffd”用UTF-8编码是多少呢，EFBFBD，用三个字节表示。UTF-8编码是可变长度的，但是我们的GBK编码是定长，2个字节。当两个UTF-8编码的�，即EFBFBD EFBFBD，被当作GBK解码的时候。就会解码成3个字符，EFBF BDEF BFBD，在GBK编码中这三个字符就是大名鼎鼎的“锟斤拷”。

###  二 [js 编码格式](https://blog.51cto.com/u_15914240/5946530)

1.  JavaScript 编码方法
    JavaScript 语言采用 Unicode 字符集，但是只支持一种编码方法。
    这种编码既不是 UTF-16，也不是 UTF-8，更不是 UTF-32。上面那些编码方法，JavaScript 都不用。
    **JavaScript 用的是 UCS-2**！ 
2.  UCS-2历史
    互联网还没出现的年代，曾经有两个团队，不约而同想搞统一字符集。一个是 1988 年成立的 Unicode 团队，另一个是 1989 年成立的 UCS 团队。等到他们发现了对方的存在，很快就达成一致：世界上不需要两套统一字符集。
    1991 年 10 月，两个团队决定合并字符集。也就是说，从今以后只发布一套字符集，就是 Unicode，并且修订此前发布的字符集，UCS 的码点将与 Unicode 完全一致。

    UCS 的开发进度快于 Unicode，1990 年就公布了第一套编码方法 UCS-2，使用 2 个字节表示已经有码点的字符。（那个时候只有一个平面，就是基本平面，所以 2 个字节就够用了。）UTF-16 编码迟至 1996 年 7 月才公布，明确宣布是 UCS-2 的超集，即基本平面字符沿用 UCS-2 编码，辅助平面字符定义了 4 个字节的表示方法。

    两者的关系简单说，就是 UTF-16 取代了 UCS-2，或者说 UCS-2 整合进了 UTF-16。所以，现在只有 UTF-16，没有 UCS-2。

    那么，为什么 JavaScript 不选择更高级的 UTF-16，而用了已经被淘汰的 UCS-2 呢？

    答案很简单：非不想也，是不能也。因为在 JavaScript 语言出现的时候，还没有 UTF-16 编码。
3.  JavaScript 字符函数的局限
    由于 JavaScript 只能处理 UCS-2 编码，造成所有字符在这门语言中都是 2 个字节，如果是 4 个字节的字符，会当作两个双字节的字符处理。JavaScript 的字符函数都受到这一点的影响，无法返回正确结果。

    ```js
    "𝌆".length
    // 2

    '\u1D306' 
    // 'ᴰ6'     如果直接在\u后面跟上超过0xFFFF的数值 会解析会两个
    '\u1D306' === '𝌆'
    // false    
    '\u{1D306}' === '𝌆'  
    // true  ES6新增功能


    "𝌆".charAt(0)
    // "�"

    "𝌆".charCodeAt(0)
    // 55348(0xD834)

    "𝌆" === '\uD834\uDF06'
    // true


    //上面代码表示，JavaScript 认为字符的长度是 2，取到的第一个字符是空字符，取到的第一个字符的码点是 0xDB34。这些结果都不正确！

    //解决这个问题，必须对码点做一个判断，然后手动调整。下面是正确的遍历字符串的写法。

    while (++index < length) {

    // ...

    if (charCode >= 0xD800 && charCode <= 0xDBFF) {

        output.push(character + string.charAt(++index));

    } else {

        output.push(character);

    }

    }

    //类似的问题存在于所有的 JavaScript 字符操作函数。

    String.prototype.replace()

    String.prototype.substring()

    String.prototype.slice()
    …
    //上面的函数都只对 2 字节的码点有效。要正确处理 4 字节的码点，就必须逐一部署自己的版本，判断一下当前字符的码点范围。
    
    ```

    